## 使用方式

`@gradio-app.md`

## 上下文

- 训练好的模型：`output/models/`
- 模型实现：`src/models.py`
- 评估指标：`src/evaluation.py`
- 模型训练配置与参数

## 可用工具

- Gradio Web 接口
- 模型推理相关库

## 流程

1. 检查 `output/models/` 是否存在训练好的模型
2. 若存在模型，创建 `src/gradio_app.py`，实现模型推理界面：
   - **模型选择**：
     - 下拉框选择可用模型
     - 显示模型信息（类型、训练时间、性能指标）
   - **输入界面**：
     - 根据模型需求动态生成输入字段
     - 支持文件上传以批量预测
     - 提供示例输入
   - **预测输出**：
     - 展示预测/分类结果
     - 输出置信度
     - （如有）展示特征重要性
     - 提供解释模块（如已实现 SHAP/LIME）
   - **批量处理**：
     - 支持上传 CSV/Excel
     - 批量处理多条输入
     - 提供结果下载
   - **模型对比**（多模型时）：
     - 并排展示预测
     - 性能对比
     - 支持集成预测
3. 实现核心功能：
   - 模型加载与缓存
   - 输入校验与预处理
   - 实时推理
   - 输出后处理
   - 边界场景的错误处理
4. 增强功能：
   - A/B 测试界面
   - 模型置信度阈值设置
   - 自定义预处理选项
5. 创建启动脚本 `scripts/launch_app.py`：
   ```python
   python scripts/launch_app.py --port 7860 --share
   ```
6. 在 `docs/11-model-deployment-guide.md` 撰写部署指南：
   - 本地部署步骤
   - API 端点说明
   - 模型服务最佳实践
   - 性能优化建议
7. 使用多种输入与边界场景测试推理效果
